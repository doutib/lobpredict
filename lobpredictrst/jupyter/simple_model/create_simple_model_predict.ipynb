{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best model parameters are given by\n",
    "```\n",
    "author : SHAMINDRA\n",
    "data_source_dir : SC_shuffle\n",
    "test_type : validation\n",
    "model_type : RF\n",
    "RF:\n",
    "    n_estimators : 100\n",
    "    criterion : 'gini'\n",
    "    max_features : 'auto'\n",
    "    max_depth : 20\n",
    "    n_jobs : 1\n",
    "SVM:\n",
    "    kernel : 'rbf'\n",
    "    degree : 3\n",
    "    gamma : 'auto'\n",
    "    tol : 0.001\n",
    "NNET:\n",
    "    method1 : 'Tanh'\n",
    "    neurons1 : 24\n",
    "    method2 : 'Tanh'\n",
    "    neurons2 : 39\n",
    "    decay : 0.0001\n",
    "    learning_rate : 0.001\n",
    "    n_iter : 25\n",
    "    random_state : 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: GaÃ«l Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked at the top features from the best performing random forest. They are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The top variables are:\n",
    "var_importance = [(1, 'P_1_bid', 0.020001165389254737)\n",
    "                  , (2, 'V_1_bid', 0.018358575666246449)\n",
    "                  , (3, 'P_1_ask', 0.017058479215839299)\n",
    "                  , (4, 'V_1_ask', 0.016953559068869958)\n",
    "                  , (5, 'P_2_bid', 0.016908649059514971)\n",
    "                  , (6, 'V_2_bid', 0.016219220215427665)\n",
    "                  , (7, 'P_2_ask', 0.015039647893425838)\n",
    "                  , (8, 'V_2_ask', 0.014497773408233052)\n",
    "                  , (9, 'P_3_bid', 0.014321084019596746)\n",
    "                  , (10, 'V_3_bid', 0.014158850118003859)\n",
    "                  , (11, 'P_3_ask', 0.014101386932514923)\n",
    "                  , (12, 'V_3_ask', 0.013911823640617986)\n",
    "                  , (13, 'P_4_bid', 0.013838322603744435)\n",
    "                  , (14, 'V_4_bid', 0.013668619218980316)\n",
    "                  , (15, 'P_4_ask', 0.013413471959983998)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open test and train sets\n",
    "df_train = pd.read_csv(train_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "df_test  = pd.read_csv(test_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "\n",
    "# Drop the first columns - they are not useful\n",
    "df_train_clean = df_train.iloc[:,1:]\n",
    "df_test_clean  = df_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_cols  =  list(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                          , 'V_2_ask']].columns.values)\n",
    "\n",
    "X_train  =  np.array(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                          , 'V_2_ask']])\n",
    "Y_train  =  np.array(df_train_clean[['labels']])[:,0]\n",
    "\n",
    "X_test  =  np.array(df_test_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                          , 'V_2_ask']])\n",
    "Y_test  =  np.array(df_test_clean[['labels']])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the labels\n",
    "labels = np.unique(Y_train)\n",
    "\n",
    "## # Scale Data\n",
    "scaler = MinMaxScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Set up the data\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# Fit\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_hat   = logreg.predict(X_test)\n",
    "Y_probs = logreg.predict_proba(X_test)\n",
    "\n",
    "## # Misclassification error rate\n",
    "miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
    "## # Log Loss\n",
    "eps = 10^(-15)\n",
    "logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
    "\n",
    "##confusion_matrix\n",
    "confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
    "                                     , labels=labels)\n",
    "\n",
    "# classification_report\n",
    "classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
    "\n",
    "# Output results in a list format\n",
    "result = []\n",
    "result.append(\"confusion_matrix\")\n",
    "result.append(confusion_matrix1)\n",
    "result.append(\"classification_report\")\n",
    "result.append(classification_report1)\n",
    "result.append(\"logloss\")\n",
    "result.append(logloss)\n",
    "result.append(\"miss_err\")\n",
    "result.append(miss_err)\n",
    "result.append(\"Y_hat\")\n",
    "result.append(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.43      0.60      0.50     18373\n",
      "          0       0.40      0.44      0.42     16950\n",
      "          1       0.38      0.17      0.24     15265\n",
      "\n",
      "avg / total       0.41      0.42      0.40     50588\n",
      "\n",
      "[-1  1 -1 ...,  0 -1 -1]\n",
      "[[ 0.4061748   0.27577677  0.31804843]\n",
      " [ 0.19159361  0.28938718  0.51901922]\n",
      " [ 0.52523662  0.20730076  0.26746262]\n",
      " ..., \n",
      " [ 0.33569901  0.43736893  0.22693206]\n",
      " [ 0.46693092  0.23000641  0.30306267]\n",
      " [ 0.38504269  0.29336207  0.32159525]]\n"
     ]
    }
   ],
   "source": [
    "print(result[3])\n",
    "print(Y_hat)\n",
    "print(Y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predicted output for our most successful RF model is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "classification_report\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "         -1       0.99      0.98      0.98     18373\n",
    "          0       0.97      0.98      0.97     16950\n",
    "          1       0.99      0.98      0.98     15265\n",
    "\n",
    "avg / total       0.98      0.98      0.98     50588\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_simple_linear(df_train_clean, df_test_clean):\n",
    "    X_train_cols  =  list(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                          , 'V_2_ask']].columns.values)\n",
    "\n",
    "    X_train  =  np.array(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                              , 'V_2_ask']])\n",
    "    Y_train  =  np.array(df_train_clean[['labels']])[:,0]\n",
    "\n",
    "    X_test  =  np.array(df_test_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                              , 'V_2_ask']])\n",
    "    Y_test  =  np.array(df_test_clean[['labels']])[:,0]\n",
    "    \n",
    "    # Define the labels\n",
    "    labels = np.unique(Y_train)\n",
    "\n",
    "    ## # Scale Data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Set up the data\n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Fit\n",
    "    logreg.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict\n",
    "    Y_hat   = logreg.predict(X_test)\n",
    "    Y_probs = logreg.predict_proba(X_test)\n",
    "\n",
    "    ## # Misclassification error rate\n",
    "    miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
    "    ## # Log Loss\n",
    "    eps = 10^(-15)\n",
    "    logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
    "\n",
    "    ##confusion_matrix\n",
    "    confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
    "                                         , labels=labels)\n",
    "\n",
    "    # classification_report\n",
    "    classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
    "\n",
    "    # Output results in a list format\n",
    "    result = []\n",
    "    result.append(\"confusion_matrix\")\n",
    "    result.append(confusion_matrix1)\n",
    "    result.append(\"classification_report\")\n",
    "    result.append(classification_report1)\n",
    "    result.append(\"logloss\")\n",
    "    result.append(logloss)\n",
    "    result.append(\"miss_err\")\n",
    "    result.append(miss_err)\n",
    "    result.append(\"Y_hat\")\n",
    "    result.append(Y_hat)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1, ...,  0, -1, -1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_simple_predict = predict_simple_linear(df_train_clean = df_train_clean\n",
    "                                              , df_test_clean = df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202349"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted outcomes\n",
    "linear_simple_predict_vals = linear_simple_predict[len(linear_simple_predict) -1]\n",
    "len(list(linear_simple_predict_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'rf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-cda231371c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'execute_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../../execute_model.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/imp.py\u001b[0m in \u001b[0;36mload_source\u001b[0;34m(name, pathname, file)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;31m# To allow reloading to potentially work, use a non-hacked loader which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# won't rely on a now-closed file object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/LEARNING/STUDY/UC_BERKELEY/STATISTICS/COURSES/MA_PROGRAM/CURRENT_COURSES/SPRING_2016/STAT222/PROJECTS/lobpredictrst/lobpredictrst/execute_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read_model_yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read_model_yaml.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'rf'"
     ]
    }
   ],
   "source": [
    "modl = imp.load_source('execute_model', '../../execute_model.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
