{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best model parameters are given by\n",
    "```\n",
    "author : SHAMINDRA\n",
    "data_source_dir : SC_shuffle\n",
    "test_type : validation\n",
    "model_type : RF\n",
    "RF:\n",
    "    n_estimators : 100\n",
    "    criterion : 'gini'\n",
    "    max_features : 'auto'\n",
    "    max_depth : 20\n",
    "    n_jobs : 1\n",
    "SVM:\n",
    "    kernel : 'rbf'\n",
    "    degree : 3\n",
    "    gamma : 'auto'\n",
    "    tol : 0.001\n",
    "NNET:\n",
    "    method1 : 'Tanh'\n",
    "    neurons1 : 24\n",
    "    method2 : 'Tanh'\n",
    "    neurons2 : 39\n",
    "    decay : 0.0001\n",
    "    learning_rate : 0.001\n",
    "    n_iter : 25\n",
    "    random_state : 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: GaÃ«l Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/output/model_clean_data/SC_shuffle/train_test_validation.tar.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source_dir   = \"SC_shuffle\"\n",
    "train_ds_name     = \"train_test_validation.tar.gz\"\n",
    "test_ds_name      = \"validation.tar.gz\"\n",
    "train_ds_ref      = \"../../data/output/model_clean_data/\" + data_source_dir + \"/\" + train_ds_name\n",
    "test_ds_ref       = \"../../data/output/model_clean_data/\" + data_source_dir + \"/\" + test_ds_name\n",
    "train_ds_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open test and train sets\n",
    "df_train = pd.read_csv(train_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "df_test  = pd.read_csv(test_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "\n",
    "# Drop the first columns - they are not useful\n",
    "df_train_clean = df_train.iloc[:,1:]\n",
    "df_test_clean  = df_test.iloc[:,1:]\n",
    "\n",
    "# Traning data column names - used for variale importance\n",
    "X_train_cols  =  list(df_train_clean.drop(['labels', 'index', 'Time'], axis=1).columns.values)\n",
    "\n",
    "# Define test/training set\n",
    "X_train  =  np.array(df_train_clean.drop(['labels', 'index', 'Time'], axis = 1))\n",
    "Y_train  =  np.array(df_train_clean[['labels']])[:,0]\n",
    "X_test   =  np.array(df_test_clean.drop(['labels', 'index', 'Time'], axis = 1))\n",
    "Y_test   =  np.array(df_test_clean[['labels']])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-52b79987e091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[0;32m-> 1142\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Define the labels\n",
    "labels = np.unique(Y_train)\n",
    "\n",
    "## # Scale Data\n",
    "scaler = MinMaxScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Set up the data\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# Fit\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict\n",
    "Y_hat   = logreg.predict(X_test)\n",
    "\n",
    "## # Misclassification error rate\n",
    "miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
    "## # Log Loss\n",
    "eps = 10^(-15)\n",
    "logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
    "\n",
    "##confusion_matrix\n",
    "confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
    "                                     , labels=labels)\n",
    "\n",
    "# classification_report\n",
    "classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
    "\n",
    "# Output results in a list format\n",
    "result = []\n",
    "result.append(\"confusion_matrix\")\n",
    "result.append(confusion_matrix1)\n",
    "result.append(\"classification_report\")\n",
    "result.append(classification_report1)\n",
    "result.append(\"logloss\")\n",
    "result.append(logloss)\n",
    "result.append(\"miss_err\")\n",
    "result.append(miss_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'P_1_bid', 0.020001165389254737),\n",
       " (2, 'V_1_bid', 0.01835857566624645),\n",
       " (3, 'P_1_ask', 0.0170584792158393),\n",
       " (4, 'V_1_ask', 0.01695355906886996),\n",
       " (5, 'P_2_bid', 0.01690864905951497),\n",
       " (6, 'V_2_bid', 0.016219220215427665),\n",
       " (7, 'P_2_ask', 0.015039647893425838),\n",
       " (8, 'V_2_ask', 0.014497773408233052),\n",
       " (9, 'P_3_bid', 0.014321084019596746),\n",
       " (10, 'V_3_bid', 0.014158850118003859),\n",
       " (11, 'P_3_ask', 0.014101386932514923),\n",
       " (12, 'V_3_ask', 0.013911823640617986),\n",
       " (13, 'P_4_bid', 0.013838322603744435),\n",
       " (14, 'V_4_bid', 0.013668619218980316),\n",
       " (15, 'P_4_ask', 0.013413471959983998)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The top variables are:\n",
    "var_importance = [(1, 'P_1_bid', 0.020001165389254737)\n",
    "                  , (2, 'V_1_bid', 0.018358575666246449)\n",
    "                  , (3, 'P_1_ask', 0.017058479215839299)\n",
    "                  , (4, 'V_1_ask', 0.016953559068869958)\n",
    "                  , (5, 'P_2_bid', 0.016908649059514971)\n",
    "                  , (6, 'V_2_bid', 0.016219220215427665)\n",
    "                  , (7, 'P_2_ask', 0.015039647893425838)\n",
    "                  , (8, 'V_2_ask', 0.014497773408233052)\n",
    "                  , (9, 'P_3_bid', 0.014321084019596746)\n",
    "                  , (10, 'V_3_bid', 0.014158850118003859)\n",
    "                  , (11, 'P_3_ask', 0.014101386932514923)\n",
    "                  , (12, 'V_3_ask', 0.013911823640617986)\n",
    "                  , (13, 'P_4_bid', 0.013838322603744435)\n",
    "                  , (14, 'V_4_bid', 0.013668619218980316)\n",
    "                  , (15, 'P_4_ask', 0.013413471959983998)]\n",
    "\n",
    "var_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
