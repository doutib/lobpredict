{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import imp\n",
    "import yaml\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from rf import *\n",
    "from svm import *\n",
    "#from nnet import *\n",
    "modl = imp.load_source('read_model_yaml', 'read_model_yaml.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import argument\n",
    "#inp_yaml = \"model/spec/SS/SS_RF_1.yaml\"\n",
    "inp_yaml = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open test and train sets\n",
    "df_test  = pd.read_csv(\"data/output/model_clean_data/test.tar.gz\",compression='gzip', index_col = None)\n",
    "df_train = pd.read_csv(\"data/output/model_clean_data/train.tar.gz\",compression='gzip', index_col = None)\n",
    "\n",
    "# Define test/training set\n",
    "X_test   =  np.array(df_test.drop(['labels'], axis = 1))\n",
    "Y_test   =  np.array(df_test[['labels']])[:,0]\n",
    "X_train  =  np.array(df_train.drop(['labels'], axis = 1))\n",
    "Y_train  =  np.array(df_train[['labels']])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def rf(X_train,\n",
      "       Y_train,\n",
      "       X_test,\n",
      "       Y_test,\n",
      "       n_estimators=10,\n",
      "       criterion=\"gini\",\n",
      "       max_features=\"auto\",\n",
      "       max_depth=-1,\n",
      "       n_jobs=1):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    ----------\n",
      "    X_train       : pandas data frame\n",
      "        data frame of features for the training set\n",
      "    Y_train       : pandas data frame\n",
      "        data frame of labels for the training set\n",
      "    X_test        : pandas data frame\n",
      "        data frame of features for the test set\n",
      "    Y_test        : pandas data frame\n",
      "        data frame of labels for the test set\n",
      "    n_estimators : integer, optional (default=10)\n",
      "        The number of trees in the forest.\n",
      "    criterion : string, optional (default=”gini”)\n",
      "        The function to measure the quality of a split.\n",
      "        Supported criteria are “gini” for the Gini impurity and “entropy”\n",
      "        for the information gain.\n",
      "    max_features : int, float, string or None, optional (default=”auto”)\n",
      "        The number of features to consider when looking for the best split:\n",
      "        If int, then consider max_features features at each split.\n",
      "        If float, then max_features is a percentage and int(max_features * n_features)\n",
      "        features are considered at each split.\n",
      "        If “auto”, then max_features=sqrt(n_features).\n",
      "        If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
      "        If “log2”, then max_features=log2(n_features).\n",
      "        If None, then max_features=n_features.\n",
      "    max_depth : integer or None, optional (default=None)\n",
      "        The maximum depth of the tree.\n",
      "        If None, then nodes are expanded until all leaves are pure or\n",
      "        until all leaves contain less than min_samples_split samples.\n",
      "        Ignored if max_leaf_nodes is not None.\n",
      "    n_jobs : integer, optional (default=1)\n",
      "        The number of jobs to run in parallel for both fit and predict.\n",
      "        If -1, then the number of jobs is set to the number of cores.\n",
      "\n",
      "    Result:\n",
      "    -------\n",
      "    numpy array\n",
      "        logloss    : averaged logarithmic loss\n",
      "        miss_err   : missclassification error rate\n",
      "        prec       : precision\n",
      "        recall     : recall\n",
      "        f1         : f1 score\n",
      "        parameters : previous parameters in the order previously specified\n",
      "    \"\"\"\n",
      "    if max_depth==-1:\n",
      "        max_depth = None\n",
      "\n",
      "    labels = np.unique(Y_train)\n",
      "\n",
      "    ## # Scale Data\n",
      "    scaler = MinMaxScaler()\n",
      "    X_test = scaler.fit_transform(X_test)\n",
      "    X_train = scaler.fit_transform(X_train)\n",
      "\n",
      "    ## # Run rf\n",
      "    # Define classifier\n",
      "    rf = RandomForestClassifier(n_estimators=n_estimators,\n",
      "                                criterion=criterion,\n",
      "                                max_features=max_features,\n",
      "                                max_depth=max_depth,\n",
      "                                n_jobs=n_jobs)\n",
      "    # Fit\n",
      "    rf.fit(X_train, Y_train)\n",
      "    # Predict\n",
      "    Y_hat = rf.predict(X_test)\n",
      "    Y_probs = rf.predict_proba(X_test)\n",
      "\n",
      "    ## # Misclassification error rate\n",
      "    miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
      "    ## # Log Loss\n",
      "    eps = 10^(-15)\n",
      "    logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
      "\n",
      "    ##confusion_matrix\n",
      "    confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
      "                                         , labels=labels)\n",
      "\n",
      "    # classification_report\n",
      "    classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
      "\n",
      "    # Output results in a list format\n",
      "    result = []\n",
      "    result.append(\"confusion_matrix\")\n",
      "    result.append(confusion_matrix1)\n",
      "    result.append(\"classification_report\")\n",
      "    result.append(classification_report1)\n",
      "    result.append(\"logloss\")\n",
      "    result.append(logloss)\n",
      "    result.append(\"miss_err\")\n",
      "    result.append(miss_err)\n",
      "    return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_results_txt(filename, result):\n",
    "    \"\"\"\n",
    "    Write results into csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        filename to output the result\n",
    "    results : list or numpy array\n",
    "        results of some simulation\n",
    "    labels : list\n",
    "        labels for the results, i.e. names of parameters and metrics\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as fp:\n",
    "        for item in result:\n",
    "            fp.write(\"%s\\n\\n\" % item)\n",
    "\n",
    "\n",
    "def run_model(inp_yaml,X_train,Y_train,X_test,Y_test):\n",
    "    \"\"\"Apply trees in the forest to X, return leaf indices.\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp_yaml : A yaml file with model specifications\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameters_dict : A python dictionary with the model specifications\n",
    "                          to be used to encode metadata for the model\n",
    "                          and pass into specific model functions e.g. random\n",
    "                          forest\n",
    "        \"\"\"    \n",
    "    \n",
    "    # Define output file name based on input\n",
    "    folder_name = re.split(\"/\",\"model/spec/SS/SS_RF_1.yaml\")[2]\n",
    "    file_name   = re.split(\"/\",\"model/spec/SS/SS_RF_1.yaml\")[3][:-5]\n",
    "    output      = 'data/output/'+folder_name+'/'+file_name+'.txt'\n",
    "    \n",
    "    # Read in and parse all parameters from the YAML file\n",
    "    yaml_params = modl.read_model_yaml(inp_yaml)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # Run RF (RANDOM FOREST)\n",
    "    #-------------------------------------------------    \n",
    "    \n",
    "    if yaml_params[\"model_type\"] == \"RF\":        \n",
    "        \n",
    "        # Extract the RF model variables from the YAML file        \n",
    "        n_estimators  = yaml_params[\"parameters\"][\"n_estimators\"]\n",
    "        criterion     = yaml_params[\"parameters\"][\"criterion\"]   \n",
    "        max_features  = yaml_params[\"parameters\"][\"max_features\"]          \n",
    "        max_depth     = yaml_params[\"parameters\"][\"max_depth\"]      \n",
    "        n_jobs        = yaml_params[\"parameters\"][\"n_jobs\"]\n",
    "        \n",
    "       \n",
    "        # Run many simulations in parallel using as many cores as necessary\n",
    "        if yaml_params[\"simulations\"]:\n",
    "            print(\"running RF WITH simulation...\")\n",
    "            # Run simulation\n",
    "            result = rf_simulation(X_train        = X_train\n",
    "                                   , Y_train      = Y_train\n",
    "                                   , X_test       = X_test\n",
    "                                   , Y_test       = Y_test\n",
    "                                   , n_estimators = n_estimators\n",
    "                                   , criterion    = criterion\n",
    "                                   , max_features = max_features\n",
    "                                   , max_depth    = max_depth)\n",
    "\n",
    "            print(\"finished - RF WITH simulation\")\n",
    "            # Write into csv\n",
    "            write_results_txt(output, result)\n",
    "            \n",
    "        # Run a single simulation\n",
    "        else:\n",
    "            print(\"running RF WITHOUT simulation...\")\n",
    "            # Run simulation\n",
    "            result = rf(X_train        = X_train\n",
    "                        , Y_train      = Y_train\n",
    "                        , X_test       = X_test\n",
    "                        , Y_test       = Y_test\n",
    "                        , n_estimators = n_estimators\n",
    "                        , criterion    = criterion\n",
    "                        , max_features = max_features\n",
    "                        , max_depth    = max_depth)\n",
    "            \n",
    "            print(\"finished - rf without simulation\")\n",
    "            # Write into csv\n",
    "            write_results_txt(output, result)\n",
    "            \n",
    "    #-------------------------------------------------\n",
    "    # Run SVM (SUPPORT VECTOR MACHINE)\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    # Extract the SVM model variables from the YAML file        \n",
    "    if yaml_params[\"model_type\"] == \"SVM\":        \n",
    "        kernel  = yaml_params[\"parameters\"][\"kernel\"] \n",
    "        degree  = yaml_params[\"parameters\"][\"degree\"]  \n",
    "        gamma   = yaml_params[\"parameters\"][\"gamma\"] \n",
    "        tol     = yaml_params[\"parameters\"][\"tol\"]\n",
    "        \n",
    "        # Define labels of output\n",
    "        labels = [\"logloss\"\n",
    "                  , \"miss_err\"\n",
    "                  , \"prec\"\n",
    "                  , \"recall\"\n",
    "                  , \"f1\"\n",
    "                  , \"C\"\n",
    "                  , \"kernel\"\n",
    "                  , \"degree\" \n",
    "                  , \"gamma\"\n",
    "                  , \"tol\"\n",
    "                  , \"decision_function_shape\"]\n",
    "        \n",
    "        # Run many simulations in parallel using as many cores as necessary\n",
    "        if yaml_params[\"simulations\"]:\n",
    "            # Run simulation\n",
    "            result = svm_simulation(X_train                   = X_train\n",
    "                                    , Y_train                 = Y_train\n",
    "                                    , X_test                  = X_test\n",
    "                                    , Y_test                  = Y_test\n",
    "                                    , kernel                  = kernel\n",
    "                                    , C                       = 1.0\n",
    "                                    , degree                  = degree \n",
    "                                    , gamma                   = gamma\n",
    "                                    , tol                     = tol\n",
    "                                    , decision_function_shape ='ovr')\n",
    "\n",
    "            # Write into csv\n",
    "            write_results_csv(output, result, labels)\n",
    "        \n",
    "        # Run a single simulation\n",
    "        else:\n",
    "            # Run simulation\n",
    "            result = svm(X_train        = X_train\n",
    "                         , Y_train      = Y_train\n",
    "                         , X_test       = X_test\n",
    "                         , Y_test       = Y_test\n",
    "                         , kernel       = kernel\n",
    "                         , C            = 1.0\n",
    "                         , degree       = degree\n",
    "                         , gamma        = gamma\n",
    "                         , tol          = tol\n",
    "                         , decision_function_shape='ovr')\n",
    "            \n",
    "            # Write into csv\n",
    "            write_results_csv(output, result, labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running RF WITHOUT simulation...\n",
      "finished - rf without simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamindra/anaconda3/envs/py3_stat222_finance/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "run_model(inp_yaml,X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
