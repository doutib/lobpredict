{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best model parameters are given by\n",
    "```\n",
    "author : SHAMINDRA\n",
    "data_source_dir : SC_shuffle\n",
    "test_type : validation\n",
    "model_type : RF\n",
    "RF:\n",
    "    n_estimators : 100\n",
    "    criterion : 'gini'\n",
    "    max_features : 'auto'\n",
    "    max_depth : 20\n",
    "    n_jobs : 1\n",
    "SVM:\n",
    "    kernel : 'rbf'\n",
    "    degree : 3\n",
    "    gamma : 'auto'\n",
    "    tol : 0.001\n",
    "NNET:\n",
    "    method1 : 'Tanh'\n",
    "    neurons1 : 24\n",
    "    method2 : 'Tanh'\n",
    "    neurons2 : 39\n",
    "    decay : 0.0001\n",
    "    learning_rate : 0.001\n",
    "    n_iter : 25\n",
    "    random_state : 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked at the top features from the best performing random forest. They are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The top variables are:\n",
    "var_importance = [(1, 'P_1_bid', 0.020001165389254737)\n",
    "                  , (2, 'V_1_bid', 0.018358575666246449)\n",
    "                  , (3, 'P_1_ask', 0.017058479215839299)\n",
    "                  , (4, 'V_1_ask', 0.016953559068869958)\n",
    "                  , (5, 'P_2_bid', 0.016908649059514971)\n",
    "                  , (6, 'V_2_bid', 0.016219220215427665)\n",
    "                  , (7, 'P_2_ask', 0.015039647893425838)\n",
    "                  , (8, 'V_2_ask', 0.014497773408233052)\n",
    "                  , (9, 'P_3_bid', 0.014321084019596746)\n",
    "                  , (10, 'V_3_bid', 0.014158850118003859)\n",
    "                  , (11, 'P_3_ask', 0.014101386932514923)\n",
    "                  , (12, 'V_3_ask', 0.013911823640617986)\n",
    "                  , (13, 'P_4_bid', 0.013838322603744435)\n",
    "                  , (14, 'V_4_bid', 0.013668619218980316)\n",
    "                  , (15, 'P_4_ask', 0.013413471959983998)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train test datasets\n",
    "train_ds_ref      = \"data/output/model_clean_data/SC_shuffle/train_test_validation.tar.gz\"\n",
    "test_ds_ref       = \"data/output/model_clean_data/SC_shuffle/strategy_validation.tar.gz\"\n",
    "\n",
    "# Open test and train sets\n",
    "df_train = pd.read_csv(train_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "df_test  = pd.read_csv(test_ds_ref\n",
    "                       , compression='gzip', index_col = None)\n",
    "\n",
    "# Drop the first columns - they are not useful\n",
    "df_train_clean = df_train.iloc[:,1:]\n",
    "df_test_clean  = df_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_simple_linear(df_train_clean, df_test_clean):\n",
    "    X_train_cols  =  list(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                          , 'V_2_ask']].columns.values)\n",
    "\n",
    "    X_train  =  np.array(df_train_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                              , 'V_2_ask']])\n",
    "    Y_train  =  np.array(df_train_clean[['labels']])[:,0]\n",
    "\n",
    "    X_test  =  np.array(df_test_clean[['P_1_bid', 'V_1_bid', 'P_1_ask', 'V_1_ask', 'P_2_bid', 'V_2_bid', 'P_2_ask'\n",
    "                                       , 'V_2_ask']])\n",
    "    Y_test  =  np.array(df_test_clean[['labels']])[:,0]\n",
    "    \n",
    "    # Define the labels\n",
    "    labels = np.unique(Y_train)\n",
    "\n",
    "    ## # Scale Data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Set up the data\n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Fit\n",
    "    logreg.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict\n",
    "    Y_hat   = logreg.predict(X_test)\n",
    "    Y_probs = logreg.predict_proba(X_test)\n",
    "\n",
    "    ## # Misclassification error rate\n",
    "    miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
    "    ## # Log Loss\n",
    "    eps = 10^(-15)\n",
    "    logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
    "\n",
    "    ##confusion_matrix\n",
    "    confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
    "                                         , labels=labels)\n",
    "\n",
    "    # classification_report\n",
    "    classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
    "\n",
    "    # Output results in a list format\n",
    "    result = []\n",
    "    result.append(\"confusion_matrix\")\n",
    "    result.append(confusion_matrix1)\n",
    "    result.append(\"classification_report\")\n",
    "    result.append(classification_report1)\n",
    "    result.append(\"logloss\")\n",
    "    result.append(logloss)\n",
    "    result.append(\"miss_err\")\n",
    "    result.append(miss_err)\n",
    "    result.append(\"Y_hat\")\n",
    "    result.append(Y_hat)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_simple_predict = predict_simple_linear(df_train_clean = df_train_clean\n",
    "                                              , df_test_clean = df_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.38      0.26      0.31     25829\n",
      "          0       0.45      0.70      0.55     31757\n",
      "          1       0.31      0.15      0.20     18721\n",
      "\n",
      "avg / total       0.39      0.42      0.38     76307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(linear_simple_predict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted outcomes\n",
    "linear_simple_predict_vals = linear_simple_predict[len(linear_simple_predict) -1]\n",
    "#len(list(linear_simple_predict_vals))\n",
    "len(list(linear_simple_predict_vals))-len(df_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf(X_train_cols,\n",
    "       X_train,\n",
    "       Y_train,\n",
    "       X_test,\n",
    "       Y_test,\n",
    "       n_estimators=10,\n",
    "       criterion=\"gini\",\n",
    "       max_features=\"auto\",\n",
    "       max_depth=-1,\n",
    "       n_jobs=1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train_cols  : list of feature column names\n",
    "        from the training set\n",
    "    X_train       : pandas data frame\n",
    "        data frame of features for the training set\n",
    "    Y_train       : pandas data frame\n",
    "        data frame of labels for the training set\n",
    "    X_test        : pandas data frame\n",
    "        data frame of features for the test set\n",
    "    Y_test        : pandas data frame\n",
    "        data frame of labels for the test set\n",
    "    n_estimators : integer, optional (default=10)\n",
    "        The number of trees in the forest.\n",
    "    criterion : string, optional (default=”gini”)\n",
    "        The function to measure the quality of a split.\n",
    "        Supported criteria are “gini” for the Gini impurity and “entropy”\n",
    "        for the information gain.\n",
    "    max_features : int, float, string or None, optional (default=”auto”)\n",
    "        The number of features to consider when looking for the best split:\n",
    "        If int, then consider max_features features at each split.\n",
    "        If float, then max_features is a percentage and int(max_features * n_features)\n",
    "        features are considered at each split.\n",
    "        If “auto”, then max_features=sqrt(n_features).\n",
    "        If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "        If “log2”, then max_features=log2(n_features).\n",
    "        If None, then max_features=n_features.\n",
    "    max_depth : integer or None, optional (default=None)\n",
    "        The maximum depth of the tree.\n",
    "        If None, then nodes are expanded until all leaves are pure or\n",
    "        until all leaves contain less than min_samples_split samples.\n",
    "        Ignored if max_leaf_nodes is not None.\n",
    "    n_jobs : integer, optional (default=1)\n",
    "        The number of jobs to run in parallel for both fit and predict.\n",
    "        If -1, then the number of jobs is set to the number of cores.\n",
    "\n",
    "    Result:\n",
    "    -------\n",
    "    numpy array\n",
    "        logloss    : averaged logarithmic loss\n",
    "        miss_err   : missclassification error rate\n",
    "        prec       : precision\n",
    "        recall     : recall\n",
    "        f1         : f1 score\n",
    "        parameters : previous parameters in the order previously specified\n",
    "    \"\"\"\n",
    "    if max_depth==-1:\n",
    "        max_depth = None\n",
    "\n",
    "    labels = np.unique(Y_train)\n",
    "\n",
    "    ## # Run rf\n",
    "    # Define classifier\n",
    "    rf = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                criterion    = criterion,\n",
    "                                max_features = max_features,\n",
    "                                max_depth    = max_depth,\n",
    "                                n_jobs       = n_jobs)\n",
    "    # Fit\n",
    "    rf.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict\n",
    "    Y_hat   = rf.predict(X_test)\n",
    "    Y_probs = rf.predict_proba(X_test)\n",
    "\n",
    "    ## # Misclassification error rate\n",
    "    miss_err = 1-accuracy_score(Y_test, Y_hat)\n",
    "    ## # Log Loss\n",
    "    eps = 10^(-15)\n",
    "    logloss = log_loss(Y_test, Y_probs, eps = eps)\n",
    "\n",
    "    ##confusion_matrix\n",
    "    confusion_matrix1 = confusion_matrix(y_true=Y_test, y_pred=Y_hat\n",
    "                                         , labels=labels)\n",
    "\n",
    "    # classification_report\n",
    "    classification_report1 = classification_report(y_true=Y_test, y_pred=Y_hat)\n",
    "\n",
    "    # Variable importance\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Return tuple of (rank, feature name, variable importance)\n",
    "    var_importance = [(f+1, X_train_cols[f], importances[indices[f]]) for f in range(X_train.shape[1])]\n",
    "\n",
    "    # Output results in a list format\n",
    "    result = []\n",
    "    result.append(\"confusion_matrix\")\n",
    "    result.append(confusion_matrix1)\n",
    "    result.append(\"classification_report\")\n",
    "    result.append(classification_report1)\n",
    "    result.append(\"number of trees\")\n",
    "    result.append(n_estimators)\n",
    "    result.append(\"max depth\")\n",
    "    result.append(max_depth)\n",
    "    result.append(\"logloss\")\n",
    "    result.append(logloss)\n",
    "    result.append(\"miss_err\")\n",
    "    result.append(miss_err)\n",
    "    result.append(\"var_importance\")\n",
    "    result.append(var_importance)\n",
    "    result.append(\"Y_hat\")\n",
    "    result.append(Y_hat)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def execute_model(inp_yaml):\n",
    "    \"\"\"Apply trees in the forest to X, return leaf indices.\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp_yaml : A yaml file with model specifications\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameters_dict : A python dictionary with the model specifications\n",
    "                          to be used to encode metadata for the model\n",
    "                          and pass into specific model functions e.g. random\n",
    "                          forest\n",
    "        \"\"\"\n",
    "\n",
    "    # Read in and parse all parameters from the YAML file\n",
    "    yaml_params = read_model_yaml(inp_yaml)\n",
    "\n",
    "    # Define output file name based on input\n",
    "    folder_name = re.split(\"/\", inp_yaml)[2]\n",
    "    file_name   = re.split(\"/\", inp_yaml)[3][:-5]\n",
    "    output_txt_file = 'data/output/' + folder_name + '/' + file_name + '.txt'\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # Create Train and Test Datasets\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    data_source_dir = yaml_params[\"data_source_dir\"]\n",
    "    test_type       = yaml_params[\"test_type\"]\n",
    "\n",
    "    print('data source dir is: %s' % (data_source_dir))\n",
    "    print('test type is: %s' % (test_type))\n",
    "\n",
    "    if test_type == \"test\":\n",
    "        train_ds_name = \"train.tar.gz\"\n",
    "        test_ds_name  = \"test.tar.gz\"\n",
    "    elif test_type == \"validation\":\n",
    "        train_ds_name = \"train_test.tar.gz\"\n",
    "        test_ds_name  = \"validation.tar.gz\"\n",
    "    else:\n",
    "        #train_ds_name = \"train_test_validation.tar.gz\"\n",
    "        #TODO - delete\n",
    "        train_ds_name = \"train_test.tar.gz\"\n",
    "        test_ds_name  = \"strategy_validation.tar.gz\"\n",
    "\n",
    "    train_ds_ref      = \"data/output/model_clean_data/\" + data_source_dir + \"/\" + train_ds_name\n",
    "    test_ds_ref       = \"data/output/model_clean_data/\" + data_source_dir + \"/\" + test_ds_name\n",
    "\n",
    "    print('training dataset is: %s' % (train_ds_ref))\n",
    "    print('test dataset is: %s' % (test_ds_ref))\n",
    "\n",
    "    # Open test and train sets\n",
    "    df_train = pd.read_csv(train_ds_ref\n",
    "                           , compression='gzip', index_col = None)\n",
    "    df_test  = pd.read_csv(test_ds_ref\n",
    "                           , compression='gzip', index_col = None)\n",
    "\n",
    "    # Drop the first columns - they are not useful\n",
    "    df_train_clean = df_train.iloc[:,1:]\n",
    "    df_test_clean  = df_test.iloc[:,1:]\n",
    "\n",
    "    # Traning data column names - used for variale importance\n",
    "    X_train_cols  =  list(df_train_clean.drop(['labels', 'index', 'Time'], axis=1).columns.values)\n",
    "\n",
    "    # Define test/training set\n",
    "    X_train  =  np.array(df_train_clean.drop(['labels', 'index', 'Time'], axis = 1))\n",
    "    Y_train  =  np.array(df_train_clean[['labels']])[:,0]\n",
    "    X_test   =  np.array(df_test_clean.drop(['labels', 'index', 'Time'], axis = 1))\n",
    "    Y_test   =  np.array(df_test_clean[['labels']])[:,0]\n",
    "\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # Run RF (RANDOM FOREST)\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    if yaml_params[\"model_type\"] == \"RF\":\n",
    "\n",
    "        # Extract the RF model variables from the YAML file\n",
    "        n_estimators  = yaml_params[\"parameters\"][\"n_estimators\"]\n",
    "        criterion     = yaml_params[\"parameters\"][\"criterion\"]\n",
    "        max_features  = yaml_params[\"parameters\"][\"max_features\"]\n",
    "        max_depth     = yaml_params[\"parameters\"][\"max_depth\"]\n",
    "        n_jobs        = yaml_params[\"parameters\"][\"n_jobs\"]\n",
    "\n",
    "        print('number of trees is: %d' % (n_estimators))\n",
    "        print('max depth is: %d' % (max_depth))\n",
    "\n",
    "        print(\"running RF WITHOUT simulation...\")\n",
    "\n",
    "        # Run simulation\n",
    "        result = rf(X_train_cols   = X_train_cols\n",
    "                    , X_train      = X_train\n",
    "                    , Y_train      = Y_train\n",
    "                    , X_test       = X_test\n",
    "                    , Y_test       = Y_test\n",
    "                    , n_estimators = n_estimators\n",
    "                    , criterion    = criterion\n",
    "                    , max_features = max_features\n",
    "                    , max_depth    = max_depth)\n",
    "\n",
    "        print(\"finished - rf without simulation\")\n",
    "\n",
    "        return result\n",
    "        # Write into text file\n",
    "        #write_results_txt(output_txt_file, result)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # Run SVM (SUPPORT VECTOR MACHINE)\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    # Extract the SVM model variables from the YAML file\n",
    "    if yaml_params[\"model_type\"] == \"SVM\":\n",
    "        kernel  = yaml_params[\"parameters\"][\"kernel\"]\n",
    "        degree  = yaml_params[\"parameters\"][\"degree\"]\n",
    "        gamma   = yaml_params[\"parameters\"][\"gamma\"]\n",
    "        tol     = yaml_params[\"parameters\"][\"tol\"]\n",
    "        C       = yaml_params[\"parameters\"][\"C\"]\n",
    "\n",
    "        print('The value of C is: %.2f' % (C))\n",
    "\n",
    "        print(\"running SVM WITHOUT simulation...\")\n",
    "\n",
    "        # Run a single simulation\n",
    "        result = svm(X_train        = X_train\n",
    "                     , Y_train      = Y_train\n",
    "                     , X_test       = X_test\n",
    "                     , Y_test       = Y_test\n",
    "                     , kernel       = kernel\n",
    "                     , C            = C\n",
    "                     , degree       = degree\n",
    "                     , gamma        = gamma\n",
    "                     , tol          = tol\n",
    "                     , decision_function_shape='ovr')\n",
    "\n",
    "        # Write into text file\n",
    "        #write_results_txt(output_txt_file, result)\n",
    "        return result\n",
    "        print(\"finished - SVM without simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_model_yaml(inp_yaml):\n",
    "    \"\"\"Apply trees in the forest to X, return leaf indices.\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp_yaml : A yaml file with model specifications\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameters_dict : A python dictionary with the model specifications\n",
    "                          to be used to encode metadata for the model\n",
    "                          and pass into specific model functions e.g. random\n",
    "                          forest\n",
    "        \"\"\"\n",
    "    # with open(\"../model/spec/SS/SS_RF_1.yaml\") as stream:\n",
    "    with open(inp_yaml) as stream:\n",
    "        data = yaml.load(stream)\n",
    "        parameters_dict = {\n",
    "        \"author\"                   : data[\"author\"]\n",
    "        , \"data_source_dir\"        : data[\"data_source_dir\"]\n",
    "        , \"model_type\"             : data[\"model_type\"]\n",
    "        , \"test_type\"              : data[\"test_type\"]        \n",
    "        , \"parameters\"             : data[data[\"model_type\"]]\n",
    "        }\n",
    "    return parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data source dir is: SC_shuffle\n",
      "test type is: strategy_validation\n",
      "training dataset is: data/output/model_clean_data/SC_shuffle/train_test.tar.gz\n",
      "test dataset is: data/output/model_clean_data/SC_shuffle/strategy_validation.tar.gz\n",
      "number of trees is: 100\n",
      "max depth is: 20\n",
      "running RF WITHOUT simulation...\n",
      "finished - rf without simulation\n"
     ]
    }
   ],
   "source": [
    "result_best_RF = execute_model(inp_yaml = \"./model/spec/TB/TB_RF_SC_shuffle_strategy_4.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.29      0.35      0.31     25829\n",
      "          0       0.45      0.26      0.33     31757\n",
      "          1       0.27      0.37      0.31     18721\n",
      "\n",
      "avg / total       0.35      0.32      0.32     76307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result_best_RF[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ds_ref       = \"data/output/model_clean_data/SC_shuffle/strategy_validation.tar.gz\"\n",
    "df_test           = pd.read_csv(test_ds_ref, compression='gzip', index_col = None)\n",
    "df_test2          = df_test\n",
    "df_test2[\"predicted\"] = list(result_best_RF[len(result_best_RF) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Direct Python to plot all figures inline (i.e., not in a separate window)\n",
    "%matplotlib inline\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Division of two integers in Python 2.7 does not return a floating point result. The default is to round down \n",
    "# to the nearest integer. The following piece of code changes the default.\n",
    "from __future__ import division\n",
    "\n",
    "def profit_calculator(data, delta_t = 30, simple = False):\n",
    "    \"\"\"Calculate the profit of trading strategy based on precisely the prediction of the model\n",
    "        Parameters\n",
    "        ----------\n",
    "        data    : a data frame with \"predicted\" \"P_1_bid\" \"P_1_ask\"\n",
    "        delta_t : time gap between \n",
    "        simple  : a dummy, True, means we make transection decisions only every delta_t period. False, means we track the current \n",
    "                  hand every period, only if we don't have anything at hand, we make new transactions\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        profit        : a numeric, the net profit at the end\n",
    "        \n",
    "        \"\"\"    \n",
    "    if simple == True:\n",
    "        data_effective = data.loc[np.arange(len(data)) % delta_t == 0]\n",
    "        bid            = data_effective['P_1_bid']\n",
    "        ask            = data_effective['P_1_ask']\n",
    "        trade_decision = data_effective['predicted'][:-1]\n",
    "        buy_profit     = np.array(bid[1:]) - np.array(ask[:-1])\n",
    "        sell_profit    = np.array(bid[:-1]) - np.array(ask[1:])\n",
    "        profit         = sum((np.array(trade_decision) > 0) * buy_profit + (np.array(trade_decision) < 0) * sell_profit)\n",
    "        return profit\n",
    "    else:\n",
    "        buy_profit           = np.array(data['P_1_bid'][delta_t:]) - np.array(data['P_1_ask'][:(-1 * delta_t)])\n",
    "        sell_profit           = np.array(data['P_1_bid'][:(-1 * delta_t)]) - np.array(data['P_1_ask'][delta_t:])\n",
    "        trade_decision_draft = data['predicted'][:(-1 * delta_t)]\n",
    "        T                    = len(buy_profit)\n",
    "        current_state        = [0] * T\n",
    "        trade_decision       = [0] * T\n",
    "        profit               = 0\n",
    "        for i in range(T):\n",
    "            if current_state[i] == 1:\n",
    "                trade_decision[i] = 0\n",
    "            else:\n",
    "                trade_decision[i] = trade_decision_draft[i]\n",
    "                    \n",
    "            if i < T-1:\n",
    "                current_state[i+1] = int(sum(abs(np.array(trade_decision[max(0, i + 1 - delta_t):i + 1]))) != 0)\n",
    "        profit = sum((np.array(trade_decision) > 0) * buy_profit + (np.array(trade_decision) < 0) * sell_profit)\n",
    "        return profit         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.950000000000159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_calculator(data = df_test2, delta_t = 1000, simple = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.989999999999782"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_calculator(data = df_test2, delta_t = 1000, simple = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
